{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tazkia1996/brain-mri-unet/blob/main/unet%2B%2B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6aPNYqf8EgV"
      },
      "source": [
        "# Image Segmentation using UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0uQ0arG8GpD",
        "outputId": "0bd8959f-e0e1-4c01-d2f0-53a0ce30c84f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install tensorflow==2.8.0"
      ],
      "metadata": {
        "id": "iJyMUo1OBt9M"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MejG3-U68Ega"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4KxX7Dm8Egd"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3_1zFaDF8Ege"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "%matplotlib inline\n",
        "import pickle\n",
        "\n",
        "import cv2\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from glob import glob\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from skimage.color import rgb2gray\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Model, load_model, save_model\n",
        "from tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnYO-XYl8Egh"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaMSyJxw8Egh"
      },
      "outputs": [],
      "source": [
        "DataPath = '/content/gdrive/MyDrive/MSC_Thesis/lgg-mri-segmentation/test/sample2/'\n",
        "\n",
        "dirs = []\n",
        "images = []\n",
        "masks = []\n",
        "for dirname, _, filenames in os.walk(DataPath):\n",
        "    for filename in filenames:\n",
        "        if 'mask'in filename:\n",
        "            dirs.append(dirname.replace(DataPath, ''))\n",
        "            masks.append(filename)\n",
        "            images.append(filename.replace('_mask', ''))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33psjEYE8Egi"
      },
      "outputs": [],
      "source": [
        "# print(masks[:10], images[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNOhPB5C8Egj"
      },
      "outputs": [],
      "source": [
        "len(dirs), len(images), len(masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJcWrZVj8Egk"
      },
      "outputs": [],
      "source": [
        "imagePath_df = pd.DataFrame({'directory':dirs, 'images': images, 'masks': masks})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rx24or0z8Egl"
      },
      "outputs": [],
      "source": [
        "imagePath_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaZeQOE28Egm"
      },
      "source": [
        "## Image Shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sU8Evvt8Egm"
      },
      "outputs": [],
      "source": [
        "def print_imShape():\n",
        "    idx = np.random.randint(0, len(imagePath_df))\n",
        "\n",
        "    imagePath = os.path.join(DataPath, imagePath_df['directory'].iloc[idx], imagePath_df['images'].iloc[idx])\n",
        "    maskPath = os.path.join(DataPath, imagePath_df['directory'].iloc[idx], imagePath_df['masks'].iloc[idx])\n",
        "\n",
        "    image = cv2.imread(imagePath)\n",
        "    mask = cv2.imread(maskPath)\n",
        "    print(\"Shape of Images \", image.shape)\n",
        "    print(\"Shape of Masks \", mask.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXaH8yBH8Egm"
      },
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "    print_imShape()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knxGW0oL8Egn"
      },
      "source": [
        "## Plot Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "027zFOcg8Egn"
      },
      "outputs": [],
      "source": [
        "def plot_images():\n",
        "    idx = np.random.randint(0, len(imagePath_df))\n",
        "\n",
        "    imagePath = os.path.join(DataPath, imagePath_df['directory'].iloc[idx], imagePath_df['images'].iloc[idx])\n",
        "    maskPath = os.path.join(DataPath, imagePath_df['directory'].iloc[idx], imagePath_df['masks'].iloc[idx])\n",
        "\n",
        "    image = cv2.imread(imagePath)\n",
        "    mask = cv2.imread(maskPath)\n",
        "\n",
        "    fig, axs = plt.subplots(1,3, figsize=[13,15])\n",
        "\n",
        "    axs[0].imshow(image)\n",
        "    axs[0].set_title('Brain MRI')\n",
        "\n",
        "    axs[1].imshow(mask)\n",
        "    axs[1].set_title('Mask')\n",
        "\n",
        "    axs[2].imshow(image)\n",
        "    axs[2].imshow(mask, alpha=0.3)\n",
        "    axs[2].set_title('MRI with mask')\n",
        "\n",
        "    plt.grid(False)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cockwIIQ8Egn"
      },
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "    plot_images()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aulGswi88Ego"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9pSkD9M8Ego"
      },
      "outputs": [],
      "source": [
        "imagePath_df['image-path'] = DataPath + imagePath_df['directory'] + '/' + imagePath_df['images']\n",
        "imagePath_df['mask-path'] = DataPath + imagePath_df['directory'] + '/' + imagePath_df['masks']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7rgUUX68Ego"
      },
      "outputs": [],
      "source": [
        "train , test = train_test_split(imagePath_df, test_size=0.25, random_state=21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m514h-H_8Ego"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 100\n",
        "BATCH_SIZE = 5\n",
        "ImgHieght = 256\n",
        "ImgWidth = 256\n",
        "Channels = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVtslLd78Egp"
      },
      "source": [
        "## Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJJJSNNB8Egp"
      },
      "outputs": [],
      "source": [
        "data_augmentation = dict(rotation_range=45.,\n",
        "                         width_shift_range=0.1,\n",
        "                         height_shift_range=0.1,\n",
        "                         shear_range=0.2,\n",
        "                         zoom_range=0.2,\n",
        "                         horizontal_flip=True,\n",
        "                         vertical_flip=True,\n",
        "                         fill_mode='reflect')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW9JGhNA8Egp"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrqNypDi8Egp"
      },
      "outputs": [],
      "source": [
        "# image generator\n",
        "imagegen = ImageDataGenerator(rescale=1./255., **data_augmentation)\n",
        "maskgen = ImageDataGenerator(rescale=1./255., **data_augmentation)\n",
        "\n",
        "\n",
        "# train generator\n",
        "timage_generator=imagegen.flow_from_dataframe(dataframe=train,\n",
        "                                            x_col=\"image-path\",\n",
        "                                            batch_size= BATCH_SIZE,\n",
        "                                            seed=42,\n",
        "                                            class_mode=None,\n",
        "                                            target_size=(ImgHieght,ImgWidth),\n",
        "                                            color_mode='rgb')\n",
        "# mask data generator\n",
        "tmask_generator=maskgen.flow_from_dataframe(dataframe=train,\n",
        "                                            x_col=\"mask-path\",\n",
        "                                            batch_size=BATCH_SIZE,\n",
        "                                            seed=42,\n",
        "                                            class_mode=None,\n",
        "                                            target_size=(ImgHieght,ImgWidth),\n",
        "                                            color_mode='grayscale')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlyDngL38Egq"
      },
      "source": [
        "### Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wVyFCeR8Egq"
      },
      "outputs": [],
      "source": [
        "# image generator\n",
        "imagegen = ImageDataGenerator(rescale=1./255.)\n",
        "maskgen = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "\n",
        "# train generator\n",
        "vimage_generator=imagegen.flow_from_dataframe(dataframe=test,\n",
        "                                            x_col=\"image-path\",\n",
        "                                            batch_size= BATCH_SIZE,\n",
        "                                            seed=42,\n",
        "                                            class_mode=None,\n",
        "                                            target_size=(ImgHieght,ImgWidth),\n",
        "                                            color_mode='rgb')\n",
        "# validation mask data generator\n",
        "vmask_generator=maskgen.flow_from_dataframe(dataframe=test,\n",
        "                                            x_col=\"mask-path\",\n",
        "                                            batch_size=BATCH_SIZE,\n",
        "                                            seed=42,\n",
        "                                            class_mode=None,\n",
        "                                            target_size=(ImgHieght,ImgWidth),\n",
        "                                            color_mode='grayscale')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8EfOH4o8Egq"
      },
      "outputs": [],
      "source": [
        "def data_iterator(image_gen, mask_gen):\n",
        "    for img, mask in zip(image_gen, mask_gen):\n",
        "        yield img, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWcLZSrG8Egq"
      },
      "outputs": [],
      "source": [
        "train_gen = data_iterator(timage_generator, tmask_generator)\n",
        "valid_gen = data_iterator(vimage_generator, vmask_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6UNsTvJdL56"
      },
      "outputs": [],
      "source": [
        "# function to create dice coefficient\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth=100):\n",
        "    y_true_flatten = K.flatten(y_true)\n",
        "    y_pred_flatten = K.flatten(y_pred)\n",
        "\n",
        "    intersection = K.sum(y_true_flatten * y_pred_flatten)\n",
        "    union = K.sum(y_true_flatten) + K.sum(y_pred_flatten)\n",
        "    return (2 * intersection + smooth) / (union + smooth)\n",
        "\n",
        "# function to create dice loss\n",
        "def dice_loss(y_true, y_pred, smooth=100):\n",
        "    return -dice_coef(y_true, y_pred, smooth)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "def jaccard_loss(y_true, y_pred):\n",
        "    y_true = Flatten()(y_true)\n",
        "    y_pred = Flatten()(y_pred)\n",
        "\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    union = tf.reduce_sum(y_true + y_pred) - intersection\n",
        "\n",
        "    jaccard_loss = 1 - (intersection + 1e-15) / (union + 1e-15)\n",
        "\n",
        "    return jaccard_loss"
      ],
      "metadata": {
        "id": "3M5PzECwCT7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg7HqDEf8Egq"
      },
      "source": [
        "## UNet++"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86q7-KNw-r-P"
      },
      "outputs": [],
      "source": [
        "nb_filter = [16,32,64,128,256]\n",
        "# Build U-Net++ model\n",
        "inputs = Input((ImgHieght, ImgWidth, Channels))\n",
        "#s = Lambda(lambda x: x / 255) (inputs)\n",
        "\n",
        "\n",
        "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (inputs)\n",
        "c1 = Dropout(0.5) (c1)\n",
        "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
        "c1 = Dropout(0.5) (c1)\n",
        "p1 = MaxPooling2D((2, 2), strides=(2, 2)) (c1)\n",
        "\n",
        "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
        "c2 = Dropout(0.5) (c2)\n",
        "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
        "c2 = Dropout(0.5) (c2)\n",
        "p2 = MaxPooling2D((2, 2), strides=(2, 2)) (c2)\n",
        "\n",
        "up1_2 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up12', padding='same')(c2)\n",
        "conv1_2 = concatenate([up1_2, c1], name='merge12', axis=3)\n",
        "c3 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_2)\n",
        "c3 = Dropout(0.5) (c3)\n",
        "c3 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
        "c3 = Dropout(0.5) (c3)\n",
        "\n",
        "conv3_1 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
        "conv3_1 = Dropout(0.5) (conv3_1)\n",
        "conv3_1 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3_1)\n",
        "conv3_1 = Dropout(0.5) (conv3_1)\n",
        "pool3 = MaxPooling2D((2, 2), strides=(2, 2), name='pool3')(conv3_1)\n",
        "\n",
        "up2_2 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up22', padding='same')(conv3_1)\n",
        "conv2_2 = concatenate([up2_2, c2], name='merge22', axis=3) #x10\n",
        "conv2_2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_2)\n",
        "conv2_2 = Dropout(0.5) (conv2_2)\n",
        "conv2_2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_2)\n",
        "conv2_2 = Dropout(0.5) (conv2_2)\n",
        "\n",
        "up1_3 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up13', padding='same')(conv2_2)\n",
        "conv1_3 = concatenate([up1_3, c1, c3], name='merge13', axis=3)\n",
        "conv1_3 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_3)\n",
        "conv1_3 = Dropout(0.5) (conv1_3)\n",
        "conv1_3 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_3)\n",
        "conv1_3 = Dropout(0.5) (conv1_3)\n",
        "\n",
        "conv4_1 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pool3)\n",
        "conv4_1 = Dropout(0.5) (conv4_1)\n",
        "conv4_1 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv4_1)\n",
        "conv4_1 = Dropout(0.5) (conv4_1)\n",
        "pool4 = MaxPooling2D((2, 2), strides=(2, 2), name='pool4')(conv4_1)\n",
        "\n",
        "up3_2 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up32', padding='same')(conv4_1)\n",
        "conv3_2 = concatenate([up3_2, conv3_1], name='merge32', axis=3) #x20\n",
        "conv3_2 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3_2)\n",
        "conv3_2 = Dropout(0.5) (conv3_2)\n",
        "conv3_2 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3_2)\n",
        "conv3_2 = Dropout(0.5) (conv3_2)\n",
        "\n",
        "up2_3 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up23', padding='same')(conv3_2)\n",
        "conv2_3 = concatenate([up2_3, c2, conv2_2], name='merge23', axis=3)\n",
        "conv2_3 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_3)\n",
        "conv2_3 = Dropout(0.5) (conv2_3)\n",
        "conv2_3 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_3)\n",
        "conv2_3 = Dropout(0.5) (conv2_3)\n",
        "\n",
        "up1_4 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up14', padding='same')(conv2_3)\n",
        "conv1_4 = concatenate([up1_4, c1, c3, conv1_3], name='merge14', axis=3)\n",
        "conv1_4 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_4)\n",
        "conv1_4 = Dropout(0.5) (conv1_4)\n",
        "conv1_4 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_4)\n",
        "conv1_4 = Dropout(0.5) (conv1_4)\n",
        "\n",
        "conv5_1 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pool4)\n",
        "conv5_1 = Dropout(0.5) (conv5_1)\n",
        "conv5_1 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv5_1)\n",
        "conv5_1 = Dropout(0.5) (conv5_1)\n",
        "\n",
        "up4_2 = Conv2DTranspose(nb_filter[3], (2, 2), strides=(2, 2), name='up42', padding='same')(conv5_1)\n",
        "conv4_2 = concatenate([up4_2, conv4_1], name='merge42', axis=3) #x30\n",
        "conv4_2 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv4_2)\n",
        "conv4_2 = Dropout(0.5) (conv4_2)\n",
        "conv4_2 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv4_2)\n",
        "conv4_2 = Dropout(0.5) (conv4_2)\n",
        "\n",
        "up3_3 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up33', padding='same')(conv4_2)\n",
        "conv3_3 = concatenate([up3_3, conv3_1, conv3_2], name='merge33', axis=3)\n",
        "conv3_3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3_3)\n",
        "conv3_3 = Dropout(0.5) (conv3_3)\n",
        "conv3_3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3_3)\n",
        "conv3_3 = Dropout(0.5) (conv3_3)\n",
        "\n",
        "up2_4 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up24', padding='same')(conv3_3)\n",
        "conv2_4 = concatenate([up2_4, c2, conv2_2, conv2_3], name='merge24', axis=3)\n",
        "conv2_4 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_4)\n",
        "conv2_4 = Dropout(0.5) (conv2_4)\n",
        "conv2_4 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_4)\n",
        "conv2_4 = Dropout(0.5) (conv2_4)\n",
        "\n",
        "up1_5 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up15', padding='same')(conv2_4)\n",
        "conv1_5 = concatenate([up1_5, c1, c3, conv1_3, conv1_4], name='merge15', axis=3)\n",
        "conv1_5 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_5)\n",
        "conv1_5 = Dropout(0.5) (conv1_5)\n",
        "conv1_5 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_5)\n",
        "conv1_5 = Dropout(0.5) (conv1_5)\n",
        "\n",
        "nestnet_output_4 = Conv2D(1, (1, 1), activation='softmax', kernel_initializer = 'he_normal',  name='output_4', padding='same')(conv1_5)\n",
        "\n",
        "model = Model([inputs], [nestnet_output_4])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=dice_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARKmZpHbThC_"
      },
      "outputs": [],
      "source": [
        "# get an instance of the model\n",
        "# define optimizer\n",
        "#adam = Adam(lr = 0.05, epsilon = 0.1)\n",
        "#model.compile(optimizer=adam, loss=bce_dice_loss, metrics=[dice_loss, dsc])\n",
        "#model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=dice_loss, metrics=[\"accuracy\", dice_coef, dice_loss])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkphlb878Egs"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuGzCwsf8Egu"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNLR-9lQ8Egu"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(patience=15, verbose=1),\n",
        "    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=1e-5, verbose=1),\n",
        "    ModelCheckpoint('/content/gdrive/MyDrive/MSC_Thesis/unetplus/modelbrainmriplus.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ybDiCyW8Egv"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "STEP_SIZE_TRAIN = timage_generator.n/BATCH_SIZE\n",
        "STEP_SIZE_TRAIN = int(math.ceil(STEP_SIZE_TRAIN))\n",
        "STEP_SIZE_VALID = vimage_generator.n/BATCH_SIZE\n",
        "STEP_SIZE_VALID = int(math.ceil(STEP_SIZE_VALID))\n",
        "\n",
        "print(STEP_SIZE_TRAIN)\n",
        "print(STEP_SIZE_VALID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-exWQ3Wh8Egv"
      },
      "outputs": [],
      "source": [
        "checkpoint = ModelCheckpoint('best_model.hdf5' ,\n",
        "                             monitor = 'val_loss',\n",
        "                             verbose = 1,\n",
        "                             save_best_only=True,\n",
        "                             mode = 'min',\n",
        "                             save_weights_only=True,\n",
        "                             save_freq='epoch'\n",
        "                            )\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3,\n",
        "                              patience=5, min_lr=0.00005)\n",
        "\n",
        "callbacks_list = [checkpoint, reduce_lr]\n",
        "\n",
        "# Fit model\n",
        "results = model.fit(train_gen,\n",
        "                    validation_data=valid_gen,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    callbacks=callbacks,\n",
        "                    epochs=EPOCHS,\n",
        "                    verbose=1,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kGLORi88Egw"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"Learning curve\")\n",
        "plt.plot(results.history[\"loss\"], label=\"loss\", color=sns.xkcd_rgb['greenish teal'])\n",
        "plt.plot(results.history[\"val_loss\"], label=\"val_loss\", color=sns.xkcd_rgb['amber'])\n",
        "plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"log_loss\")\n",
        "plt.legend()\n",
        "# plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5wy6NTc8Egx"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dr_nsbz8Egx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "# Load the model using Keras's built-in load_model function\n",
        "#model = keras.models.load_model('/content/gdrive/MyDrive/MSC_Thesis/unetplus/modelbrainmriplus.h5')\n",
        "\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "# Define the path to the saved model\n",
        "#model_path = '/content/gdrive/MyDrive/MSC_Thesis/unetplus/modelbrainmriplus.h5'\n",
        "\n",
        "# Load the saved model\n",
        "#loaded_model = load_model(model_path, custom_objects={'dice_loss': dice_loss, 'dice_coef': dice_coef})\n",
        "\n",
        "# Now you can use loaded_model for inference or further training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eV3GnwtZ8Egy"
      },
      "outputs": [],
      "source": [
        "eval_results = model.evaluate(valid_gen, steps=STEP_SIZE_VALID, verbose=1)\n",
        "\n",
        "print(\"Test Loss: \", eval_results[0])\n",
        "print(\"Test Accuracy: \", eval_results[1])\n",
        "print(\"Test Dice: \", eval_results[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcS2w83y8Egz"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    idx = np.random.randint(0, len(imagePath_df))\n",
        "\n",
        "    imagePath = os.path.join(DataPath, imagePath_df['directory'].iloc[idx], imagePath_df['images'].iloc[idx])\n",
        "    maskPath = os.path.join(DataPath, imagePath_df['directory'].iloc[idx], imagePath_df['masks'].iloc[idx])\n",
        "\n",
        "    image = cv2.imread(imagePath)\n",
        "    mask = cv2.imread(maskPath)\n",
        "\n",
        "    img = cv2.resize(image ,(ImgHieght, ImgWidth))\n",
        "    img = img / 255\n",
        "    img = img[np.newaxis, :, :, :]\n",
        "    pred=model.predict(img)\n",
        "\n",
        "    plt.figure(figsize=(12,12))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(np.squeeze(img))\n",
        "    plt.title('Original Image')\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(mask)\n",
        "    plt.title('Original Mask')\n",
        " #   plt.subplot(1,3,3)\n",
        " #   plt.imshow(np.squeeze(pred))\n",
        "  #  plt.title('Prediction')\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(np.squeeze(pred) > 0.5)\n",
        "    if (np.squeeze(pred) > 0.5).any():\n",
        "      label = \"Prediction: Tumor Present\"\n",
        "    else:\n",
        "      label = \"Prediction: No Tumor\"\n",
        "    plt.title(label)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B841VPw8Egz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}